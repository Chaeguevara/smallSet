{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('../datasets/train.csv')\n",
    "test = pd.read_csv('../datasets/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Before we start exploring embeddings lets write a couple of helper functions to run Logistic Regression and calculate evaluation metrics\n",
    "\n",
    "Since we want to optimize our model for F1-Scores, for all models we'll first predict the probability of the positive class. We'll then use these probabilities to get the Precision-Recall curve and from here we can select a threshold value that has the highest F1-score. To predict the labels we can simply use this threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "sns.set_palette(\"muted\")\n",
    "    \n",
    "\n",
    "def calc_f1(p_and_r):\n",
    "    p, r = p_and_r\n",
    "    return (2*p*r)/(p+r)\n",
    "\n",
    "\n",
    "# Print the F1, Precision, Recall, ROC-AUC, and Accuracy Metrics \n",
    "# Since we are optimizing for F1 score - we will first calculate precision and recall and \n",
    "# then find the probability threshold value that gives us the best F1 score\n",
    "\n",
    "def print_model_metrics(y_test, y_test_prob,y_pred,label_list,name):\n",
    "    print(\"*\"*5)\n",
    "    print(name)\n",
    "    print(\"roc\")\n",
    "    print(roc_auc_score(y_test,y_test_prob,labels = label_list,multi_class='ovr',average=\"weighted\"))\n",
    "    print(\"f1\")\n",
    "    print(metrics.f1_score(y_test,y_pred,labels=label_list,average=\"weighted\"))\n",
    "    print(\"acc\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Run Simple Log Reg Model and Print metrics\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Continuous, Categorical, Integer\n",
    "import ast\n",
    "# Run log reg 10 times and average the result to reduce predction variance\n",
    "def run_log_reg(train_features, test_features, y_train, y_test, lbl_to_idx, idx_to_lbl,label_list,feature_name, apply=True):\n",
    "    y_train_idx = [lbl_to_idx[label] for label in y_train]\n",
    "    y_test_idx = [lbl_to_idx[label] for label in y_test]\n",
    "    label_idx = [i for i in range(len(label_list))]\n",
    "    models = [\n",
    "       MultinomialNB(),\n",
    "       SVC(probability=True),\n",
    "       RandomForestClassifier(),\n",
    "#       XGBClassifier(),\n",
    "       \n",
    "    ]\n",
    "    model_names=[\n",
    "        \"Naive bayes\",\n",
    "        \"SVM\",\n",
    "        \"RF\",\n",
    "#        \"XGBoost\"\n",
    "\n",
    "    ]\n",
    "    model_prams=[\n",
    "        {'alpha' : Continuous(0.01,0.5,distribution=\"log-uniform\")},\n",
    "        {\"kernel\" : Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "         \"C\" : Continuous(0.1,50,distribution=\"uniform\")\n",
    "        },\n",
    "        {\n",
    "            \"n_estimators\" : Integer(10,100),\n",
    "            \"max_depth\" : Integer(5,50),\n",
    "            \"min_samples_split\" : Integer(2,11),\n",
    "            \"min_samples_leaf\" : Integer(1,11),\n",
    "            \"criterion\" : Categorical([\"gini\", \"entropy\", \"log_loss\"]),\n",
    "            \"max_features\" : Integer(1,13)\n",
    "        }\n",
    "    ]\n",
    "    non_negs = [\"BOW\", \"TF-IDF\"]\n",
    "    if apply == True:\n",
    "        print(feature_name)\n",
    "        computed_params = pd.read_csv(f\"../result/all_params/{feature_name}.csv\", encoding='utf-8')\n",
    "        computed_params = computed_params.drop(columns=[\"Unnamed: 0\"])\n",
    "        compute_dict = computed_params.to_dict('dict')\n",
    "\n",
    "        result_dict ={}\n",
    "        for model,name in zip(models,model_names):\n",
    "            if feature_name not in non_negs and name ==\"Naive bayes\":\n",
    "                continue\n",
    "            clf = model\n",
    "            if name in compute_dict:\n",
    "                clf = model.set_params(**ast.literal_eval(compute_dict[name][0]))\n",
    "            clf.fit(train_features,y_train_idx)\n",
    "            y_test_prob = clf.predict_proba(test_features)\n",
    "            y_pred = clf.predict(test_features)\n",
    "            print_model_metrics(y_test_idx, y_test_prob, y_pred, label_idx,name)\n",
    "\n",
    "\n",
    "\n",
    "    pre_comp_best =[]\n",
    "    \n",
    "    random.seed(1)\n",
    "    cv = cv = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "\n",
    "    if apply:\n",
    "        return\n",
    "    for model, model_name, model_param in zip(models, model_names, model_prams):\n",
    "        try:\n",
    "            evolved_estimator = GASearchCV(estimator=model,\n",
    "                               cv=cv,\n",
    "                               scoring='accuracy',\n",
    "                               population_size=10,\n",
    "                               generations=35,\n",
    "                               param_grid=model_param,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=True,\n",
    "                               keep_top_k=4)        \n",
    "            evolved_estimator.fit(train_features,y_train_idx)\n",
    "            print(evolved_estimator.best_params_)\n",
    "            pre_comp_best.append({model_name :evolved_estimator.best_params_})\n",
    "        except ValueError:\n",
    "            print(\"hi\")\n",
    "    print(pre_comp_best)\n",
    "    #y_test_prob = model.predict_proba(test_features)\n",
    "    #y_pred = model.predict(test_features)\n",
    "    #print_model_metrics(y_test_idx,y_test_prob,y_pred,label_idx)\n",
    "    df = pd.DataFrame(pre_comp_best)\n",
    "    df.to_csv(f\"../result/all_search/{feature_name}.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Bag-of-Words, TF-IDF and Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 2: 1, 5: 2, 6: 3, 8: 4, 11: 5, 13: 6, 14: 7, 15: 8, 16: 9, 18: 10, 19: 11, 21: 12, 27: 13, 28: 14, 32: 15, 33: 16, 39: 17, 42: 18, 44: 19, 46: 20, 50: 21, 53: 22}\n",
      "{0: 0, 1: 2, 2: 5, 3: 6, 4: 8, 5: 11, 6: 13, 7: 14, 8: 15, 9: 16, 10: 18, 11: 19, 12: 21, 13: 27, 14: 28, 15: 32, 16: 33, 17: 39, 18: 42, 19: 44, 20: 46, 21: 50, 22: 53}\n",
      "(325,)\n",
      "(169,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list= sorted(list(set(test.label.values)))\n",
    "lbl_to_idx = {item:i for i,item in enumerate(label_list)}\n",
    "idx_to_lbl = {i:item for i,item in enumerate(label_list)}\n",
    "print(lbl_to_idx)\n",
    "print(idx_to_lbl)\n",
    "y_train = train.label\n",
    "y_test = test.label\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "len(set(y_train.values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Bag of Words\n",
    "Let's start with simple Bag-Of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW\n",
      "*****\n",
      "Naive bayes\n",
      "roc\n",
      "0.9971063268788243\n",
      "f1\n",
      "0.8832843612233645\n",
      "acc\n",
      "0.893491124260355\n",
      "*****\n",
      "SVM\n",
      "roc\n",
      "0.9929615063098315\n",
      "f1\n",
      "0.8833631041211363\n",
      "acc\n",
      "0.893491124260355\n",
      "*****\n",
      "RF\n",
      "roc\n",
      "0.9954018640580207\n",
      "f1\n",
      "0.9243200614492016\n",
      "acc\n",
      "0.9349112426035503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer()\n",
    "x_train = bow.fit_transform(train.title.values)\n",
    "x_test = bow.transform(test.title.values)\n",
    "\n",
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list,feature_name=\"BOW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## TF-IDF\n",
    "\n",
    "TFIDF should perform better than BoW since it uses document frequencies to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "*****\n",
      "Naive bayes\n",
      "roc\n",
      "0.9972862406171837\n",
      "f1\n",
      "0.8956672832927013\n",
      "acc\n",
      "0.9053254437869822\n",
      "*****\n",
      "SVM\n",
      "roc\n",
      "0.9955755050701972\n",
      "f1\n",
      "0.939688255470134\n",
      "acc\n",
      "0.9408284023668639\n",
      "*****\n",
      "RF\n",
      "roc\n",
      "0.9938325162740105\n",
      "f1\n",
      "0.905940364311405\n",
      "acc\n",
      "0.9171597633136095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "x_train = tfidf.fit_transform(train.title.values)\n",
    "x_test = tfidf.transform(test.title.values)\n",
    "\n",
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list,feature_name=\"TF-IDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF(Normalize)\n",
    "\n",
    "TFIDF should perform better than BoW since it uses document frequencies to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def things_to_unit(a):\n",
    "    \"if 0.5km kind of that appears, convert to unitLength etc\"\n",
    "    doc_units = pd.read_excel(\"./normalizer/units.xlsx\")\n",
    "    doc_dict = dict(zip(doc_units[\"from\"],doc_units[\"to\"])) \n",
    "    for from_ in doc_dict:\n",
    "        idx = np.where(\n",
    "                 np.char.count(a,from_)==1\n",
    "              )\n",
    "        a[idx] = doc_dict[from_] \n",
    "    return a\n",
    "\n",
    "class LemmaPlaceTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`','(',')']\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        val = []\n",
    "        for t in word_tokenize(doc):\n",
    "            if t.isdigit():\n",
    "                val.append(\"unitN\")\n",
    "            elif (t not in self.ignore_tokens):\n",
    "                val.append(\n",
    "                    self.wnl.lemmatize(t,get_wordnet_pos(t))\n",
    "                )\n",
    "        new_val = np.array(val)\n",
    "        new_val = np.apply_along_axis(things_to_unit, 0, new_val)\n",
    "        return new_val\n",
    "\n",
    "def preprocess(document):\n",
    "    'changes document to lower case and removes stopwords'\n",
    "\n",
    "    # change sentence to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize into words\n",
    "    words = word_tokenize(document)\n",
    "\n",
    "    # remove stop words & numbrs\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\") or not word.isdigit()]\n",
    "\n",
    "\n",
    "    # join words to make sentence\n",
    "    document = \" \".join(words)\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "TFIDF performs marginally better than BoW. Although whats impressive here is the fact that we're getting an F1 score of 0.826 with just 50 datapoints. This is why Log Reg + TFIDF is a great baseline for NLP classification tasks.\n",
    "\n",
    "Next we'll try 100D glove vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Load the glove vectors with PyMagnitude\n",
    "# PyMagnitude is a fantastic library that handles a lot of word vectorization tasks. \n",
    "\n",
    "from pymagnitude import *\n",
    "from collections.abc import MutableMapping\n",
    "glove = Magnitude(\"../vectors/glove.6B.100d.magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d7/wr0_38q17_38rmx4dysxdyfh0000gn/T/ipykernel_3214/3747255845.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for title in tqdm_notebook(df.title.values):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25936497d209488887b8e51d98f39945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c127ef11b449eda937fe9c6387a8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll use Average Glove here \n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "def avg_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df.title.values):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x_train = avg_glove(train)\n",
    "x_test = avg_glove(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list,feature_name=\"GLOVE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT\n",
      "*****\n",
      "SVM\n",
      "roc\n",
      "0.9727600248077499\n",
      "f1\n",
      "0.7352760009476428\n",
      "acc\n",
      "0.746268656716418\n",
      "*****\n",
      "RF\n",
      "roc\n",
      "0.951664896784059\n",
      "f1\n",
      "0.5728609698758953\n",
      "acc\n",
      "0.6119402985074627\n"
     ]
    }
   ],
   "source": [
    "x_train = np.genfromtxt(\"../datasets/train_feature_bert-base-uncased.csv\",delimiter=\",\")\n",
    "x_test = np.genfromtxt(\"../datasets/test_feature_bert-base-uncased.csv\",delimiter=\",\")\n",
    "y_train = np.genfromtxt(\"../datasets/train_label_bert-base-uncased.csv\",delimiter=\",\")\n",
    "y_test = np.genfromtxt(\"../datasets/test_label_bert-base-uncased.csv\",delimiter=\",\")\n",
    "\n",
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list,feature_name=\"BERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SenBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENBERT\n",
      "*****\n",
      "SVM\n",
      "roc\n",
      "0.9491645780328376\n",
      "f1\n",
      "0.701820981671728\n",
      "acc\n",
      "0.7164179104477612\n",
      "*****\n",
      "RF\n",
      "roc\n",
      "0.9495676228027575\n",
      "f1\n",
      "0.666571902392798\n",
      "acc\n",
      "0.6865671641791045\n"
     ]
    }
   ],
   "source": [
    "x_train = np.genfromtxt(\"../datasets/train_feature_sbert.csv\",delimiter=\",\")\n",
    "x_test = np.genfromtxt(\"../datasets/test_feature_sbert.csv\",delimiter=\",\")\n",
    "y_train = np.genfromtxt(\"../datasets/train_label_sbert.csv\",delimiter=\",\")\n",
    "y_test = np.genfromtxt(\"../datasets/test_label_sbert.csv\",delimiter=\",\")\n",
    "\n",
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list,feature_name=\"SENBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electra\n",
      "*****\n",
      "SVM\n",
      "roc\n",
      "0.9477035652920343\n",
      "f1\n",
      "0.6754975124378111\n",
      "acc\n",
      "0.7014925373134329\n",
      "*****\n",
      "RF\n",
      "roc\n",
      "0.9367162980321985\n",
      "f1\n",
      "0.6191624296101909\n",
      "acc\n",
      "0.6567164179104478\n"
     ]
    }
   ],
   "source": [
    "x_train = np.genfromtxt(\"../datasets/train_feature_electra-small-discriminator.csv\",delimiter=\",\")\n",
    "x_test = np.genfromtxt(\"../datasets/test_feature_electra-small-discriminator.csv\",delimiter=\",\")\n",
    "y_train = np.genfromtxt(\"../datasets/train_label_electra-small-discriminator.csv\",delimiter=\",\")\n",
    "y_test = np.genfromtxt(\"../datasets/test_label_electra-small-discriminator.csv\",delimiter=\",\")\n",
    "\n",
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list,feature_name=\"Electra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNET\n",
      "*****\n",
      "SVM\n",
      "roc\n",
      "0.9827484215017316\n",
      "f1\n",
      "0.7934536110655515\n",
      "acc\n",
      "0.7910447761194029\n",
      "*****\n",
      "RF\n",
      "roc\n",
      "0.9511822368571887\n",
      "f1\n",
      "0.6960927960927961\n",
      "acc\n",
      "0.7164179104477612\n"
     ]
    }
   ],
   "source": [
    "x_train = np.genfromtxt(\"../datasets/train_feature_fnet-base.csv\",delimiter=\",\")\n",
    "x_test = np.genfromtxt(\"../datasets/test_feature_fnet-base.csv\",delimiter=\",\")\n",
    "y_train = np.genfromtxt(\"../datasets/train_label_fnet-base.csv\",delimiter=\",\")\n",
    "y_test = np.genfromtxt(\"../datasets/test_label_fnet-base.csv\",delimiter=\",\")\n",
    "\n",
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list, feature_name=\"FNET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNET\n",
      "*****\n",
      "SVM\n",
      "roc\n",
      "0.8891042563933151\n",
      "f1\n",
      "0.6358589172022007\n",
      "acc\n",
      "0.6567164179104478\n",
      "*****\n",
      "RF\n",
      "roc\n",
      "0.8689497313925576\n",
      "f1\n",
      "0.5444013697745042\n",
      "acc\n",
      "0.5522388059701493\n"
     ]
    }
   ],
   "source": [
    "x_train = np.genfromtxt(\"../datasets/train_feature_roberta-base.csv\",delimiter=\",\")\n",
    "x_test = np.genfromtxt(\"../datasets/test_feature_roberta-base.csv\",delimiter=\",\")\n",
    "y_train = np.genfromtxt(\"../datasets/train_label_roberta-base.csv\",delimiter=\",\")\n",
    "y_test = np.genfromtxt(\"../datasets/test_label_roberta-base.csv\",delimiter=\",\")\n",
    "\n",
    "run_log_reg(x_train, x_test, y_train, y_test, lbl_to_idx=lbl_to_idx, idx_to_lbl=idx_to_lbl, label_list=label_list, feature_name=\"FNET\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('smallData')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "204ba388238a6e55b9feb9487e3d718d3b3259521e8492c709b3886a91f63210"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
